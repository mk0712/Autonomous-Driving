{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NumPy:\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SciPy:\n",
    "import scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn:\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow:\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0rc2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tqdm for batches and viz:\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Math\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matplotlib Pyplot:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ComputerVision:\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IPython:\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras:\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JSON for storing model:\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV for loading model:\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_file = \"/home/mk/Desktop/T1/P3/driving_log.csv\"\n",
    "model_json = '/home/mk/Desktop/T1/P3/model.json'\n",
    "model_h5 = '/home/mk/Desktop/T1/P3/model.h5'\n",
    "model_json_2 = '/home/mk/Desktop/T1/P3/model_2.json'\n",
    "model_h5_2 = '/home/mk/Desktop/T1/P3/model_2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load y (i.e., log data): \n",
    "data_driving_log = []\n",
    "with open( y_file ) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for x_i in reader:\n",
    "        data_driving_log.append(x_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_driving_log_size =  5796\n"
     ]
    }
   ],
   "source": [
    "# Size of y: \n",
    "data_driving_log_size = len(data_driving_log)\n",
    "print(\"data_driving_log_size = \", data_driving_log_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define vectors: \n",
    "X = () \n",
    "y = () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for loading X (i.e., input images):\n",
    "def getImage(feature_in_csv, j):\n",
    "    image_file = feature_in_csv[j].strip() # path and file name of image\n",
    "    #print(image_file)\n",
    "    \n",
    "    # Load and display original image:\n",
    "    \n",
    "    #plt.subplot(221)\n",
    "    img = plt.imread( image_file ) # original image 160x320 pixels\n",
    "    #plt.title(\"Original image (160x320x3 px)\", fontsize=8)\n",
    "    #plt.imshow(img)\n",
    "    #print(img.shape)\n",
    "    \n",
    "    \n",
    "    # Load, preprocess and display image:\n",
    "    \n",
    "    # Pre-process option 1: only keep every 2nd pixel (= reduce size by 1-100%/2=50%)\n",
    "    #img_preprocessed1 = img[ 50:150:2, ::2, ] # cut image y-axis[(150-50)/2] x x-axis[(320-0)/2] pixels = 50x160 pixels\n",
    "    #plt.subplot(222)\n",
    "    #plt.title(\"Pre-processed image 1 (50x160x3 px)\", fontsize=8)\n",
    "    #plt.imshow(img_preprocessed1)\n",
    "    #print(img_preprocessed1.shape)\n",
    "    \n",
    "    # Pre-process option 2: only keep every 5th pixel (= reduce size by 1-100%/5=80%)\n",
    "    img_preprocessed2 = img[ 50:150:5, ::5, ] # cut image y-axis[(150-50)/5] x x-axis[(320-0)/5] pixels = 20x64 pixels\n",
    "    #plt.subplot(223)\n",
    "    #plt.title(\"Pre-processed image 2 (20x64x3 px)\", fontsize=8)\n",
    "    #plt.imshow(img_preprocessed2)\n",
    "    #print(img_preprocessed2.shape)\n",
    "    \n",
    "    # Pre-process option 3: only keep every 10th pixel (= reduce size by 1-100%/10=90%)\n",
    "    #img_preprocessed3 = img[ 50:150:10, ::10, ] # cut image y-axis[(150-50)/10] x x-axis[(320-0)/10] pixels = 10x32 pixels\n",
    "    #plt.subplot(224)\n",
    "    #plt.title(\"Pre-processed image 3 (10x32x3 px)\", fontsize=8)\n",
    "    #plt.imshow(img_preprocessed3)\n",
    "    #print(img_preprocessed3.shape)\n",
    "    \n",
    "    img_=img_preprocessed2 # set the smallest image size that still clearly shows the track and curbs\n",
    "    image_list = img_.flatten().tolist()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5796/5796 [01:06<00:00, 86.70items/s]\n"
     ]
    }
   ],
   "source": [
    "for datapoint in tqdm( range(int(len(data_driving_log))), unit='items' ):\n",
    "    for center_left_right in range(3): \n",
    "        X = X + (getImage(data_driving_log[datapoint],center_left_right),) # center is csv-feature 0; left is csv-feature 1; right is csv-feature 2\n",
    "        y = y + (float(data_driving_log[datapoint][3]),) # y is csv-feature 3\n",
    "\n",
    "#X = np.array(X).reshape(len(X), 50, 160, 3) # pre-process option 1\n",
    "X = np.array(X).reshape(len(X), 20, 64, 3) # pre-process option 2\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (17388, 20, 64, 3)\n",
      "y.shape =  (17388,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape = \", X.shape)\n",
    "print(\"y.shape = \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into (a) train/validation data and (b) test data:\n",
    "# X_train --> X_train_valid; y_train --> y_train_valid\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split( \n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_valid.shape =  (15649, 20, 64, 3)\n",
      "X_test.shape =  (1739, 20, 64, 3)\n",
      "y_train_valid.shape =  (15649,)\n",
      "y_test.shape =  (1739,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_valid.shape = \", X_train_valid.shape)\n",
    "print(\"X_test.shape = \", X_test.shape)\n",
    "\n",
    "print(\"y_train_valid.shape = \", y_train_valid.shape)\n",
    "print(\"y_test.shape = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split train/validation data into (a) train data and (b) validation data:\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid,\n",
    "    y_train_valid,\n",
    "    test_size=0.3,\n",
    "    random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape =  (10954, 20, 64, 3)\n",
      "X_valid.shape =  (4695, 20, 64, 3)\n",
      "y_train.shape =  (10954,)\n",
      "y_valid.shape =  (4695,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape = \", X_train.shape)\n",
    "print(\"X_valid.shape = \", X_valid.shape)\n",
    "\n",
    "print(\"y_train.shape = \", y_train.shape)\n",
    "print(\"y_valid.shape = \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries in training data =  10954\n",
      "Entries in validation data =  4695\n",
      "Entries in testing data =  1739\n",
      "X_train.shape[1:] =  (20, 64, 3)\n",
      "x_i_size (i.e., features per image): 3840\n"
     ]
    }
   ],
   "source": [
    "train_size = X_train.shape[0]\n",
    "valid_size = X_valid.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "x_height_px = X_train.shape[1]\n",
    "x_width_px = X_train.shape[2]\n",
    "x_channel_count = X_train.shape[3]\n",
    "\n",
    "print(\"Entries in training data = \", train_size)\n",
    "print(\"Entries in validation data = \", valid_size)\n",
    "print(\"Entries in testing data = \", test_size)\n",
    "print(\"X_train.shape[1:] = \", X_train.shape[1:])\n",
    "print(\"x_i_size (i.e., features per image):\", x_height_px * x_width_px * x_channel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Norm:\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test  /= 255\n",
    "X_train -= 0.5\n",
    "X_valid -= 0.5\n",
    "X_test  -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model parameters:\n",
    "epochs = 25 \n",
    "batch_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape[1:] =  (20, 64, 3)\n",
      "X_train_shape_var =  (20, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape[1:] = \", X_train.shape[1:])\n",
    "X_train_shape_var = X_train.shape[1:]\n",
    "print(\"X_train_shape_var = \", X_train_shape_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Try to load existing model, use ADAM MSE, and load weights:\n",
    "    with open(model_json, 'r') as jfile:\n",
    "        model = model_from_json(json.load(jfile))\n",
    "    model.compile(\"adam\", \"mse\")\n",
    "    model.load_weights(model_h5)\n",
    "    \n",
    "except:\n",
    "    # Create a new model:\n",
    "    model = Sequential()\n",
    "    kernel_size_3x3 = (3, 3)\n",
    "    kernel_size_5x5 = (5, 5)\n",
    "    pool_size = (2, 2)\n",
    "    \n",
    "    # Convolutions:\n",
    "    conv1 = 48 \n",
    "    conv2 = 48 \n",
    "    conv3 = 32 \n",
    "    conv4 = 20 \n",
    "    conv5 = 12 \n",
    "    \n",
    "    # Layer 1 Convolution:\n",
    "    model.add( Convolution2D( conv1, kernel_size_5x5[0], kernel_size_5x5[1], border_mode='valid', \n",
    "                             input_shape=X_train.shape[1:] ) )\n",
    "    # Layer 1 ReLU:\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    # Layer 2 Convolution:\n",
    "    model.add( Convolution2D( conv2, kernel_size_5x5[0], kernel_size_5x5[1] ) )\n",
    "    # Layer 2 ReLU:\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    # Layer 3 Convolution:\n",
    "    model.add( Convolution2D( conv3, kernel_size_5x5[0], kernel_size_5x5[1] ) )\n",
    "    # Layer 3 ReLU:\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    # Layer 4 Convolution: \n",
    "    model.add( Convolution2D( conv4, kernel_size_3x3[0], kernel_size_3x3[1] ) )\n",
    "    # Layer 4 ReLU:\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    # Layer 5 Convolution: \n",
    "    model.add( Convolution2D( conv5, kernel_size_3x3[0], kernel_size_3x3[1] ) )\n",
    "    # Layer 5 ReLU:\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    # Max. Pooling: \n",
    "    model.add( MaxPooling2D( pool_size=pool_size ) )\n",
    "    \n",
    "    model.add( Dropout(0.25) ) \n",
    "\n",
    "    model.add( Flatten() )\n",
    "    \n",
    "    model.add( Dense(16) )\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    model.add( Dense(16) )\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    model.add( Dense(16) )\n",
    "    model.add( Activation('relu') )\n",
    "    \n",
    "    model.add( Dropout(0.5) )\n",
    "    \n",
    "    model.add( Dense(1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 60, 48)    3648        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 60, 48)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 12, 56, 48)    57648       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 12, 56, 48)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 8, 52, 32)     38432       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 52, 32)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 6, 50, 20)     5780        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 6, 50, 20)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 4, 48, 12)     2172        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 4, 48, 12)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 2, 24, 12)     0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2, 24, 12)     0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 576)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 16)            9232        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 16)            272         activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 16)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            272         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 16)            0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 117473\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print out summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model using Adam optimizer \n",
    "# and loss computed by mean squared error\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1739, 20, 64, 3)\n",
      "(1739,)\n"
     ]
    }
   ],
   "source": [
    "#import hcx\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10954 samples, validate on 4695 samples\n",
      "Epoch 1/25\n",
      "10954/10954 [==============================] - 178s - loss: 0.0353 - acc: 0.6449 - val_loss: 0.0434 - val_acc: 0.6371\n",
      "Epoch 2/25\n",
      "10954/10954 [==============================] - 178s - loss: 0.0352 - acc: 0.6465 - val_loss: 0.0420 - val_acc: 0.6405\n",
      "Epoch 3/25\n",
      "10954/10954 [==============================] - 178s - loss: 0.0344 - acc: 0.6462 - val_loss: 0.0430 - val_acc: 0.6368\n",
      "Epoch 4/25\n",
      "10954/10954 [==============================] - 179s - loss: 0.0344 - acc: 0.6464 - val_loss: 0.0427 - val_acc: 0.6366\n",
      "Epoch 5/25\n",
      "10954/10954 [==============================] - 179s - loss: 0.0337 - acc: 0.6470 - val_loss: 0.0424 - val_acc: 0.6354\n",
      "Epoch 6/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0341 - acc: 0.6464 - val_loss: 0.0428 - val_acc: 0.6388\n",
      "Epoch 7/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0329 - acc: 0.6473 - val_loss: 0.0429 - val_acc: 0.6366\n",
      "Epoch 8/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0335 - acc: 0.6462 - val_loss: 0.0414 - val_acc: 0.6394\n",
      "Epoch 9/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0320 - acc: 0.6491 - val_loss: 0.0420 - val_acc: 0.6386\n",
      "Epoch 10/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0331 - acc: 0.6474 - val_loss: 0.0420 - val_acc: 0.6394\n",
      "Epoch 11/25\n",
      "10954/10954 [==============================] - 179s - loss: 0.0316 - acc: 0.6481 - val_loss: 0.0397 - val_acc: 0.6396\n",
      "Epoch 12/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0319 - acc: 0.6493 - val_loss: 0.0408 - val_acc: 0.6403\n",
      "Epoch 13/25\n",
      "10954/10954 [==============================] - 179s - loss: 0.0314 - acc: 0.6492 - val_loss: 0.0408 - val_acc: 0.6400\n",
      "Epoch 14/25\n",
      "10954/10954 [==============================] - 181s - loss: 0.0302 - acc: 0.6490 - val_loss: 0.0414 - val_acc: 0.6394\n",
      "Epoch 15/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0309 - acc: 0.6485 - val_loss: 0.0423 - val_acc: 0.6394\n",
      "Epoch 16/25\n",
      "10954/10954 [==============================] - 179s - loss: 0.0302 - acc: 0.6488 - val_loss: 0.0415 - val_acc: 0.6403\n",
      "Epoch 17/25\n",
      "10954/10954 [==============================] - 181s - loss: 0.0301 - acc: 0.6487 - val_loss: 0.0413 - val_acc: 0.6411\n",
      "Epoch 18/25\n",
      "10954/10954 [==============================] - 181s - loss: 0.0283 - acc: 0.6502 - val_loss: 0.0418 - val_acc: 0.6383\n",
      "Epoch 19/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0308 - acc: 0.6497 - val_loss: 0.0410 - val_acc: 0.6409\n",
      "Epoch 20/25\n",
      "10954/10954 [==============================] - 182s - loss: 0.0291 - acc: 0.6486 - val_loss: 0.0405 - val_acc: 0.6396\n",
      "Epoch 21/25\n",
      "10954/10954 [==============================] - 181s - loss: 0.0286 - acc: 0.6494 - val_loss: 0.0401 - val_acc: 0.6430\n",
      "Epoch 22/25\n",
      "10954/10954 [==============================] - 183s - loss: 0.0278 - acc: 0.6499 - val_loss: 0.0416 - val_acc: 0.6396\n",
      "Epoch 23/25\n",
      "10954/10954 [==============================] - 186s - loss: 0.0277 - acc: 0.6497 - val_loss: 0.0423 - val_acc: 0.6394\n",
      "Epoch 24/25\n",
      "10954/10954 [==============================] - 183s - loss: 0.0296 - acc: 0.6493 - val_loss: 0.0418 - val_acc: 0.6398\n",
      "Epoch 25/25\n",
      "10954/10954 [==============================] - 180s - loss: 0.0275 - acc: 0.6503 - val_loss: 0.0420 - val_acc: 0.6396\n",
      "Test score: 0.0382249014203\n",
      "Test accuracy: 0.653824036734\n"
     ]
    }
   ],
   "source": [
    "### Model training\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=epochs,\n",
    "                    verbose=1, validation_data=(X_valid, y_valid))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create JSON and h5 files:\n",
    "if model_json_2 in os.listdir():\n",
    "    mj = model.to_json()\n",
    "    with open(model_json_2, 'w') as f:\n",
    "        json.dump(mj, f)\n",
    "        model.save_weights(model_h5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
